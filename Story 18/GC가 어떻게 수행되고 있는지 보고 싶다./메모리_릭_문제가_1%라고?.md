# Overview

---

18장 마지막 글에서는 메모리릭 문제가 발생하는 경우가 1%라고 적혀있다. 과연그럴까? 사실 틀린 말은 아니다. 정상적인 애플리케이션이 만들었을 때 예상하지 못한 트래픽이 있었더라도 처리율 제한 단위랑 애플리케이션, 네트워크 트래픽양에서 오류가 발생한다. 하지만 역으로 생각하면 메모리 릭 문제가 흔하게 발생할 수 있는 시스템이 있다. 푸시 발송 시스템이다.

![image](https://user-images.githubusercontent.com/66561524/188299374-abf619f7-4e4b-45ed-a432-dd6e88bf9705.png)

이전 회사는 20만 회원을 가진 e-commerce 가까운 플랫폼이었다. 프로덕트 서비스는 캐싱을 사용해서 트래픽을 관리하며 회원들에게는 push, 메시지, 이메일 등으로 관리를 한다.

이커머스 특징상 이벤트를 많이한다. 회원에게 이벤트를 알릴 수 있는 합법적이면서도 가장 접근성이 좋은 방법은 푸시 알림이다. 우리가 출시했던 이벤트의 대부분은 ‘선착순’ 방식이었다. 빠르게 구매를 하도록 유도한다거나 쿠폰 코드를 입력하는 방식이었다. 회원의 입장에서 푸시를 늦게 받으면 콤플레인이 무지하게 들어오는 상황이다.

# 다량 푸시 메시지 발송

---

처음에 대량이라고 글을 쓰려다가 다량이라고 글을 바꿨다. 10만건정도의 푸시를 대량으로 생각할 수 없다. 하지만 우리는 푸시메시지 10만건을 보내기 위해 적당한 크기의 EC2 인스턴스에서 발송을 했다. 하지만 당시 한 번에 푸시를 보낼 수 있는 건은 100건이었다.

문제는 발송하는 푸시 메시지를 저장해야한 다는 점이다. 어떤 푸시 메시지가 발송이 되었고 어떤 메시지가 발송되지 않았는지 어드민 화면에서 확인해야 했기 때문입니다. 그래서 Transaction을 분리해야했다.

또한 실시간으로 발송하기 위해서는 순차적인 발송을 할 수 없었다. 이유는 Firebase Cloud를 이용해서 발송을 하고 있었든데 100건을 한 단위로 보낼 수 있어 발송의 결과를 기다려야 했습니다. 따라서 첫 발송 메시지와 마지막 발송 메시지의 시간 차이가 10분이 넘게 되는 것이다.

@Async 키워드를 사용하여 멀티 스레드 방식으로 병렬처리를 하였다. 병렬처리를 하니 속도가 붙어서 빠르게 발송을 할 수 있었다. 그런데 회원의 숫자가 어느 지점에 다다르자 OOME가 발생했다.

```kotlin
2021-06-09 02:58:09.736 ERROR [nio-8080-exec-9] [o.a.c.c.C.[.[.[.[dispatcherServlet]] log (175): Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler dispatch failed; nested exception is java.lang.OutOfMemoryError: Java heap space] with root cause
java.lang.OutOfMemoryError: Java heap space
```

이 문제를 해결하기 위해 가장 쉽게 생각할 수 있는 방법은 서버의 크기를 늘리는 것이다. 하지만 메인 인스턴스의 서버의 크기를 2주~3주에 한 번하는 이벤트로 늘린다는 게 부자연스러웠다. 또한 푸시 메시지 서버를 추가하기에도 낭비라고 생각했다. 그렇다고 푸시만으로 다른 인프라를 추가할 수는 없는 노릇이었다.

그래서 JVM의 구조를 찾아봤다.

![image](https://user-images.githubusercontent.com/66561524/188299378-52da9625-1dce-4f0b-9b37-b18b164f693d.png)

[(JVM) Garbage Collection Basic](https://perfectacle.github.io/2019/05/07/jvm-gc-basic/)

가장 중요한것은 heap size와 perm size의 균형을 맞추는 것이었다. 일단 현재 서버에서 사용하고 있는 heap size와 perm size(java8부터 meta size로 변경)의 용량을 체크했다.

-command

```bash
# heap size
java -XX:+PrintFlagsFinal -version | grep -iE 'heapsize|permsize|threadstacksize'
# meta size
java -XX:+PrintFlagsFinal -version -server | grep MetaspaceSize
```

JVM 테스트를 위해 로컬에서 테스트를 했다. 그런데 문제가 발생했다. 로컬에서는 OOME가 발생하지 않는 것이다. 이유는 OS의 메모리 사양이 다르기 때문이었다.

로컬(Mac os)

```bash
java -XX:+PrintFlagsFinal -version | grep -iE 'heapsize|permsize|threadstacksize'
     intx CompilerThreadStackSize                   = 0                                   {pd product}
    uintx ErgoHeapSizeLimit                         = 0                                   {product}
    uintx HeapSizePerGCThread                       = 87241520                            {product}
    uintx InitialHeapSize                          := 268435456                           {product}
    uintx LargePageHeapSizeThreshold                = 134217728                           {product}
    uintx MaxHeapSize                              := 4294967296                          {product}
     intx ThreadStackSize                           = 1024                                {pd product}
     intx VMThreadStackSize                         = 1024                                {pd product}
openjdk version "1.8.0_282"
OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_282-b08)
OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.282-b08, mixed mode)
➜  ~ java -XX:+PrintFlagsFinal -version -server | grep MetaspaceSize
    uintx InitialBootClassLoaderMetaspaceSize       = 4194304                             {product}
    uintx MaxMetaspaceSize                          = 18446744073709547520                    {product}
    uintx MetaspaceSize                             = 21807104                            {pd product}
openjdk version "1.8.0_282"
OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_282-b08)
OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.282-b08, mixed mode)
```

개발 서버

```bash
ubuntu@ip-172-31-22-25:~/apps/api/logs$ java -XX:+PrintFlagsFinal -version | grep -iE 'heapsize|permsize|threadstacksize'
     intx CompilerThreadStackSize                   = 0                                   {pd product}
    uintx ErgoHeapSizeLimit                         = 0                                   {product}
    uintx HeapSizePerGCThread                       = 87241520                            {product}
    uintx InitialHeapSize                          := 33554432                            {product}
    uintx LargePageHeapSizeThreshold                = 134217728                           {product}
    uintx MaxHeapSize                              := 522190848                           {product}
     intx ThreadStackSize                           = 1024                                {pd product}
     intx VMThreadStackSize                         = 1024                                {pd product}
openjdk version "1.8.0_292"
OpenJDK Runtime Environment (build 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10)
OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)
ubuntu@ip-172-31-22-25:~/apps/api/logs$ java -XX:+PrintFlagsFinal -version -server | grep MetaspaceSize
    uintx InitialBootClassLoaderMetaspaceSize       = 4194304                             {product}
    uintx MaxMetaspaceSize                          = 18446744073709547520                    {product}
    uintx MetaspaceSize                             = 21807104                            {pd product}
openjdk version "1.8.0_292"
OpenJDK Runtime Environment (build 1.8.0_292-8u292-b10-0ubuntu1~18.04-b10)
OpenJDK 64-Bit Server VM (build 25.292-b10, mixed mode)
```

로컬 환경의 heap size는 4 기가바이트 이며 개발 환경은 512 메가 바이트이다. 무려 8배가 차이가 난다. 따라서 로컬 환경과 개발 환경은 같은 로직을 적용하기 어려운 상황인 것이다.

jstat을 활용한 실시간 모니터링

```bash
# jstat -gc -h{몇 줄마다 헤더가 보이게 하는지} -t {pid 번호} {몇초에 한번 로그가 찍히는지}
jstat -gc -h10 -t 23213 1000
```

[Java jstat로 메모리 모니터링](https://5dol.tistory.com/182)

jvm 메모리 분석

[[JAVA 메모리 트러블 슈팅] 콘솔에서 JVM Heap 메모리 추적하기 : jstat, jmap](https://gem1n1.tistory.com/89)

```

# 프로세스 쓰레드 확인
ps -p {pid} -T

# jmap -heap {pid}
heap 분석

# 클래스별 메모리 분석
jmap -histo:live {pid} | more

# heap dump 생성
jmap -dump:live,file=./heapdump.bin {pid}

# heap dump jhat으로 분석(DNS로 접속
# jhat -J-Xmx6g -port 7000 ./heapdump.bin
jhat -J-Xmx{memory_size} -port {port} {heap_dump_path}
```

[JMap, JHat으로 Heap Dump 분석](https://cselabnotes.com/kr/2021/03/26/jmap-jhat%EC%9C%BC%EB%A1%9C-heap-dump-%EB%B6%84%EC%84%9D/)

다양한 방법으로 JVM의 해결방법을 찾아봤다. JVM의 Heap을 Dump를 떠서 메모리 공간을 비교하고 generation의 사이즈를 임의로 조정하여서 개발서버에서 테스트를 진행했었다. 결과 실시간으로 스레드를 10개가 돌아가며 generation 메모리가 초과되어 에러가 발생하는 것을 확인할 수 있었고, jstat과 로깅으로 발생되는 메시지 숫자를 확인해가며 최적의 스레드 객체 보유량을 찾아내는 노력을 했엇다.

실제로는 `CompleteFuture` 객체의 사용과 스레드 풀 조정, 최신 Firebase의 Cloud 서비스 capacity가 100건 → 500건으로 상향이 되어 그 방법으로 해결을 했다. 결국 JVM의 조정으로 직접 해결하지는 못했지만 JVM의 구조를 파악하여 원인을 확인한 경험이었다.

아직 겪을 일이 아니라고 생각하는 JVM의 문제는 의외로 간단하게 발생할 수 있는 문제이다. 오히려 작은 회사로 갈수록 더 실무자에게 와닿는 문제일 수도 있다. JVM을 공부하는 데 조금 더 관심을 갖고 해결하는 방법을 찾아야 한다.

# Reference

---

[천만 명의 사용자에게 1분 내로 알림 보내기 (병렬프로세스의 최적화)](https://taetaetae.github.io/2019/01/02/faster-parallel-processes/)
